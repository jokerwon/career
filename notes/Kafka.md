# Kafka

### 一、初识 Kafka

消息：Kafka 的数据单元，相较于数据库的一个数据行或一条记录。

批次：一组消息，这些消息属于同一个主题和分区。

主题：Kafka 的消息通过主题分类，相较于数据库的表，或者文件系统的文件夹。

分区：主题可以被分为若干个分区，一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取。**分区可以分布在不同的服务器上，也就是说一个主题可以横跨多个服务器。**

Kafka 特点：

1. 多个生产者
2. 多个消费者
3. 基于磁盘的数据存储
4. 伸缩性
5. 高性能





### 二、生产者

#### 2.1  生产者配置

**必选配置**

##### 1.  bootstrap.servers

指定 broker 的地址清单，地址的格式为 host:port。

##### 2.  key.serializer

必选设置（**即使不发送键**），且必须被设置为一个实现了 org.apache.kafka.common.serialization.Seralizer 接口的类。Kafka 客户端默认提供了 ByteArraySerializer、StringSerializer 和 IntegerSerializer，因此常见的几种 Java 对象类型就没必要实现自己的序列化器。

##### 3.  value.serializer

同 key.serializer。

<hr>
**其他配置**

##### 4.  acks

acks 指定必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。

- acks=0，生产者在成功写入消息之前不会等待任何来自服务器的响应。
- acks=1，只要集群首领节点收到消息，生产者就会收到来自服务器的成功响应。
- acks=all，只有当所有参与复制的节点全部收到消息时，生产者才会收到成功响应。

##### 5.  buffer.memory

设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者缓冲区空间不足。此时 send() 方法调用会被阻塞或抛出异常，这取决于 **max.block.ms** 参数（表示抛出异常前可以阻塞的时间）。

##### 6.  compression.type

默认情况下消息发送时不会被压缩。该参数可设置为 snappy、gzip 或 lz4，指定消息被发送给 broker 之前使用哪一种算法进行压缩。

##### 7.  retries

指定生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误。默认情况下，生产者会在每次重试之间等待 100ms，不过可以通过 **retry.backoff.ms** 参数来设置这个时间间隔。

##### 8.  batch.size

当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照**字节数**计算（而不是消息个数）。当批次被填满，批次里的所有消息会被发送出去。不过生产者并不一定都会等到批次被填满才发送，半满的批次甚至只包含一个消息的批次也有可能被发送。

##### 9  linger.ms

指定生产者在发送批次之前等待更多消息加入批次的时间， KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去，就算批次里只有一个消息。所以把该参数设置成一个比 0 大的数能提升吞吐量。

##### 10.  client.id

该参数可以是任意的字符串，服务器会用它来识别消息的来源，还可以用在日志和配额指标里。

##### 11.  max.in.flight.requests.per.connection

指定生产者在收到服务器响应之前可以发送的最大请求数。它的值越高就会占用越多的内存，但是吞吐量也会越高。将其**设为 1 可以保证消息是按照发送的顺序写入服务器**的，即使发生了重试。

##### 12.  timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms

request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间；metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间；timeout.ms 指定了 broker 等待同步副本返回消息确认的时间，与 acks 的配置相匹配——如果在指定时间内没有收到同步副本的确认，那么 broker 就会返回一个错误。

##### 13.  max.block.ms

指定在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞，当阻塞时间达到该参数设置的值时，生产者会抛出超时异常。

##### 14.  max.request.size

用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小。例如，假设该参数值为 1MB，那么可以发送的单个最大消息为 1MB，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息的大小为 1KB。另外，broker 对可接收的消息最大值也有自己的限制（**message.max.bytes**），所以两边的配置最好可以匹配，避免生产者发送的消息被 broker 拒绝。

##### 15.  receive.buffer.bytes 和 send.buffer.bytes

分别指定了 TCP socket 接收和发送数据包的缓冲区大小。如果它们被设置为 -1，就使用操作系统的默认值。



#### 2.2  分区

Kafka 消息的键有两个用途：①作为消息的附加信息；②用来决定消息被写到主题的哪个分区。这就导致，如果一个进程只从一个主题的分区读取数据，那么具有相同键的所有消息都会被该消费者读取。

如果消息的键为 null，并且使用了默认的分区器，那么消息将被分区器使用**轮询**算法随机均衡地发送到主题内的各个可用的分区。

如果消息的键不为 null，并且使用了默认的分区器，那么 Kafka  会对键进行散列，然后根据散列值把消息映射到特定的分区上。**同一个键总是被映射到同一个分区上，因此映射时所有的分区会被使用**，而不仅仅是可用分区。如果写入数据的分区是不可用的，就会发生错误。





### 四、消费者

Kafka 消费者从属于消费者组。一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。

消费者组之间互不影响。

再均衡：分区的所有权从一个消费者转移到另一个消费者。再均衡期间，消费者无法读取消息，整个群组小段时间不可用。当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失，它有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序。

消费者通过向被指派为**群组协调器**的broker（不同的群组可以有不同的协调器）发送**心跳**来维持从属关系和它们对分区的所有权关系。如果消费者停止发送心跳的时间足够长，会被认为已死亡，再均衡就会被触发。

#### 4.1  消费者配置

**必选配置**

##### 1.  bootstrap.servers

##### 2.  key.deserializer

##### 3.  value.deserializer

<hr>

**其他配置**

##### 4.  group.id

指定消费者属于哪一个消费者群组。

##### 5.  fetch.min.bytes

指定消费者从服务器获取消息的最小字节数。broker 在收到消费者的数据请求时，如果可用的数据量小于该参数指定的大小，那么它会等到有足够的可用数据时才把数据返回给消费者。

##### 6.  fetch.max.wait.ms

指定 broker 的等待时间，默认值为 500ms。如果没有足够的数据流入 Kafka ，消费者获取 最小数据量的要求就得不到满足，最终会导致 500ms 的延迟。

##### 7.  max.partiton.fetch.bytes

指定服务器从每个分区里返回给消费者的最大字节数，默认值为 1MB。

##### 8.  session.timeout.ms

指定消费者在被认为死亡之前可以与服务器断开连接的时间，默认为 3s。如果消费者没有在该参数指定的时间内发送心跳给群组协调器，就被认为已经死亡。该参数与  **heartbeat.interval.ms** 紧密相关。heartbeat.interval.ms 指定消费者向协调器发送心跳的频率，而 session.timeout.ms 则指定了消费者可以多久不发送心跳。一般 heartbeat.interval.ms 设置的值是 session.timeout.ms 的三分之一。

##### 9. auto.offset.reset

指定消费者在读取一个没有偏移量的分区或者偏移量无效的情况（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该如何处理，默认值是 latest，即在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。另一个值是 earliest，即从起始位置读取分区的记录。

##### 10.  enable.auto.commit

指定消费者是否自动提交偏移量，默认为 true。如果该参数设置为 true，还可通过设置 **auto.commit.interval.ms** 属性来控制提交的频率。

##### 11.  client.id

用来标识从客户端发送过来的消息，通常被用在日志、度量指标和配额里。

##### 12.  max.poll.records

用于控制单词调用 call() 方法能够返回的记录数量，可以控制在轮询里需要处理的数据量。

##### 13.  receive.buffer.bytes 和 send.buffer.bytes

用来设置 socket 在读写数据时用到的 TCP 缓冲区的大小。如果被设置为 -1，就使用操作系统的默认值。

##### 14.  partition.assignment.strategy

指定分区的分配策略。Kafka 有两个默认的分配策略，分别是 **Range** 和 **RoundRobin**。也可以使用自定义策略，此时该参数的值就是自定义类的名字。

**Range**：默认使用的是 org.apache.kafka.clients.consumer.RangeAssignor 。该策略把若干个连续的分区分配给消费者。

**RoundRobin**：该策略把主题的所有分区逐个分配给消费者。